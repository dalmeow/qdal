# Research cycle

![](https://img.shields.io/badge/Area-Research_methods-blue)

In @sec-res-meth, you learned about the research process, which includes the research context, data acquisition, data analysis and communication. A different perspective on the research process that highlights the temporal succession of the process steps is the [research cycle]{.smallcaps}, represented in an idealised form in @fig-res-cycle.

![The research cycle](img/res-process-cycle.png){#fig-res-cycle fig-align="center" width="500"}

The cycle starts with the development of **research questions and hypotheses**. This step involves a thorough literature review and the identification of the topic, research problem, goal, questions and, possibly, hypotheses (as described in @sec-res-context). Once the research questions and hypotheses have been determined, the researcher proceeds with the **design of the study** which sets out to answer the research questions and assess the research hypotheses. The study design process includes determining a large number of interconnected aspects, like materials, procedures, data management and data analysis plans, target population, sampling method and so on. At times the study design process reveals shortcomings or unforeseen aspects of the research questions/hypotheses which can be updated accordingly.

Once the study design has been finalised, one proceeds with **acquiring data** based on the protocols detailed in their plan. After the completion of data acquisition, researchers **analyse data** and **interpret the results** in light of the research questions and hypotheses. Finally, the outcomes of the study are **published** in some form and the **next study cycle** begins once again.

This sounds all very reasonable, but in reality, the researchers' practice is quite different. This chapter introduces the concept of "researcher's degrees of freedom" and describes the so-called Questionable Research Practices (QRPs). We will review literature that shows the grim reality of how common QRPs are. In @sec-open-research, you will learn about principles and tools that are designed to help minimise the presence and impact of QRPs in one's own research.

## Researcher's degrees of freedom

::: {.callout-important appearance="simple"}
This section is reproduced from @coretta2023 (CC-BY-NC) with minor edits.
:::

Data analysis involves many decisions, such as how to operationalise and measure a given phenomenon or behavior, which data to submit to statistical modeling and which to exclude in the final analysis, or which inferential approach to employ. This "freedom" can be problematic because humans show cognitive biases that can lead to erroneous inferences [@tversky1974]. For example, humans are prone to see coherent patterns even in the absence of them [@brugger2001], convince themselves of the validity of prior expectations by cherry-picking evidence (aka confirmation bias, "I knew it"; @nickerson1998), and perceive events as being plausible in hindsight ("I knew it all along"; @fischhoff1975). In conjunction with an academic incentive system that rewards certain discovery processes more than others [@koole2012; @sterling1959], we often find ourselves exploring many possible analytic pathways but reporting only a selected few depending on the quality of the narrative that we can achieve with them.

This issue is particularly amplified in fields in which the raw data lend themselves to many possible ways of being measured [@roettger2019]. Combined with a wide variety of conceptual and methodological traditions as well as varying levels of quantitative training across sub-fields, the inherent flexibility of data analysis might lead to a vast plurality of analytic approaches that can itself lead to different scientific conclusions [@roettger2019a]. Analytic flexibility has been widely discussed from a conceptual point of view [@nosek2014; @simmons2011; @wagenmakers2012] and in regard to its application in individual scientific fields (e.g., @charles2019; @roettger2019a; @wicherts2016). This notwithstanding, there are still many unknowns regarding the extent of analytic plurality in practice.

Consequently, a substantial body of published articles likely present overconfident interpretations of data and statistical results based on idiosyncratic analytic strategies (e.g., @gelman2014a; @simmons2011). These interpretations, and the conclusions that derive from them, are thus associated with an unknown degree of uncertainty (dependent on the strength of evidence provided) and with an unknown degree of generalizability (dependent on the chosen analysis). Moreover, the same data could lead to very different conclusions depending on the analytic path taken by the researcher. However, instead of being critically evaluated, scientific results often remain unchallenged in the publication record.

## Questionable Research Practices
