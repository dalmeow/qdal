# Regression models {#sec-regression}

![](https://img.shields.io/badge/Area-R-green)

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(brms)
library(bayesplot)
```

In @sec-reg-intro you were introduced to regression models. Regression is a statistical model based on the equation of a straight line, with added error.

$$
y = \beta_0 + \beta_1 x + \epsilon
$$

$\beta_0$ is the regression line's intercept and $\beta_1$ is the slope of the line. We have seen that $\epsilon$ is assumed to be from a Gaussian distribution with mean 0 and standard deviation $\sigma$.

$$
\begin{align}
y & \sim Gaussian(\mu, \sigma)\\
\mu & = \beta_0 + \beta_1 x\\
\end{align}
$$

From now on, we will use the latter way of expressing regression models, because it makes it clear which distribution we assume the variable $y$ to be generated by (here, a Gaussian distribution). Note that in the wild, variables very rarely are generated by Gaussian distributions. It is just pedagogically convenient to start with Gaussian regression models (i.e. regression models with a Gaussian distribution as the distribution of the outcome variable $y$) because the parameters of the Gaussian distribution, $\mu$ and $\sigma$ can be interpreted straightforwardly on the same scale as the outcome variable $y$: so for example if $y$ is in centimetres, then the mean and standard deviation are in centimetres, if $y$ is in Hz, then the mean and SD are in Hz, and so on. Similarly, the regression $\beta$ coefficients will be on the same scale as the outcome variable $y$. You will be introduced later to regression models with distributions other than the Gaussian, where the regression parameters are estimated on a different scale than that of the outcome variable $y$.

The goal of the Gaussian regression model expressed in the formulae above is to estimate $\beta_0$, $\beta_1$ and $\sigma$ from observed data. Now, since truly Gaussian data is difficult to come by, especially in linguistics, for the sake of pedagogical simplicity we will start the learning journey on fitting regression models using data, vowel durations, for which a Gaussian regression is generally not appropriate. You will learn in Week 8 more appropriate distribution families for this type of data.

## Vowel duration in Italian: the data

We will analyse the duration of vowels in Italian from @coretta2019k and how speech rate affects vowel duration. Vowel duration should be pretty straightforward, and speech rate is simply the number of syllables per second, calculated from the frame sentence the vowel was uttered in. An expectation we might have is that vowels get shorter with increasing speech rate. You will notice how this is a very vague hypothesis: how shorter do they get? Is the shortening the same across all speech rates, or does it get weaker with higher speech rates? Our expectation/hypothesis simply states that vowels get shorter with increasing speech rate. Maybe we could do better and use what we know from speech production and come up with something more precise, but this type of vague hypothesis are very common, if not standard, in linguistic research, so we will stick to it for practical and pedagogical reasons. Remember, however, that robust research should strive for precision. In short, we will try to answer the following research question:

> What is the relationship between vowel duration and speech rate?

Let's load the R data file `coretta2018a/ita_egg.rda`. It contains several phonetic measurements obtained from audio and electroglottographic recordings. You can find the information on the data in the related entry on the QM Data website: [Electroglottographic data on Italian](https://uoelel.github.io/qml-data/data/coretta2018a/ita_egg.html).

```{r}
#| label: ita-egg

load("data/coretta2018a/ita_egg.rda")

ita_egg
```

Let's plot vowel duration and speech rate in a scatter plot. The relevant columns in the tibble are `v1_duration` and `speech_rate`. The points in the plot are the individual observations (measurements) of vowels in the 19 speakers of Italian.

```{r}
#| label: fig-vow-rate
#| fig-cap: "Scatter plot of speech rate (as number of syllables per second) and vowel duration (in milliseconds) in 19 Italian speakers."

ita_egg |> 
  ggplot(aes(speech_rate, v1_duration)) +
  geom_point(alpha = 0.5) +
  labs(
    x = "Speech rate (syllables per second)",
    y = "Vowel duration (ms)"
  )
```

You might be wondering what is the warning about missing values. This is because some observations of vowel duration (`v1_duration`) in the data are missing (i.e. they are `NA`, "Not Available"). We can drop them from the tibble using `drop_na()`. This function takes column names as arguments: each row that has `NA` in any of the columns listed in the function will be dropped, so be careful when using `drop_na()` without listing columns because any `NA` value in any column with make the row be removed.

```{r}
#| label: ita-egg-clean

ita_egg_clean <- ita_egg |> 
  drop_na(v1_duration)
```

We will use `ita_egg_clean` for the rest of the tutorial. Let's reproduce the plot, but let's add a **regression line**. This is the straight line we have been talking about, the line that is reconstructed by regression models. It is sometimes useful to add the regression line to the scatter plots to show the linear relationship of the two variables in the plot. We can quickly add regression lines to scatter plots with the smooth geometry: `geom_smooth(method = "lm")`. The `method` argument lets us pick the type of method to create the "smooth": here, we want a regression line so we choose `lm` for linear model (remember, linear model is another term for regression model). Under the hood, `geom_smooth()` fits a regression model to estimate the regression line and plots it. We will fit our own regression model below, so for now the regression line is just for show. @fig-vow-rate-lm shows the scatter plot with the regression line. You can ignore the message about the formula.

```{r}
#| label: fig-vow-rate-lm
#| fig-cap: "Relationship between speech rate (as number of syllables per second) and vowel duration (in milliseconds) in 19 Italian speakers."

ita_egg_clean |> 
  ggplot(aes(speech_rate, v1_duration)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm") +
  labs(
    x = "Speech rate (syllables per second)",
    y = "Vowel duration (ms)"
  )
```

By glancing at the individual points, we can see a negative relationship between speech rate and vowel duration: vowels get shorter with greater speech rate. This is reflected by the regression line too, which has a *negative* slope. A negative slope means that when the values on the *x*-axis increase, the values on the *y*-axis decrease. When the opposite is true, i.e. when with increasing *x*-axis values you observe increasing *y*-axis values, we say the regression line has *positive* slope. Positive and negative slope correspond to what some call a *direct* and *inverse* relationship. In terms of the equation of the line $y = \beta_0 + \beta_1 x$, a *positive slope* means $\beta_1$ is a *positive* number and, conversely, a *negative slope* means $\beta_1$ is a *negative* number. When $\beta_0$ is zero, then the regression line is flat and we say that the two variables are independent: changing one, does not systematically change the other. You explored these features of the regression slope in @sec-reg-intro, when playing around with the [Linear Models Illustrated](https://stefanocoretta.shinyapps.io/lines/) app and when answering the quiz.

::: callout-tip
### Direct/positive and inverse/negative relationship

When the slope $\beta_1$ is positive, the regression line has **positive slope** and $x$ and $y$ have a **direct relationship**.

When the slope $\beta_0$ is negative, the regression line has **negative slope** and $x$ and $y$ have an **inverse relationship**.

When the slope $\beta_0$ is `0` zero, the regression line is flat and $x$ and $y$ are **independent**.
:::

@fig-vow-rate-lm looks very nice, but the plot doesn't tell us much about the estimates for $\beta_0$ and $\beta_1$. For that, we need to actually fit the regression model.

### The model

Let's move on onto fitting a Gaussian regression model to vowel duration as the outcome variable and speech rate as the predictor. We are assuming that vowel duration follows a Gaussian distribution (although as mentioned at the beginning of this chapter, this is not the case, but it will do for now). Here is the model we will fit, in mathematical notation.

$$
\begin{align}
vdur & \sim Gaussian(\mu, \sigma)\\
\mu & = \beta_0 + \beta_1 \cdot sr\\
\end{align}
$$

You can read that as:

-   Vowel duration ($\text{vdur}$) is distributed ($\sim$) according to a Gaussian distribution ($Gaussian(\mu, \sigma)$).

-   The mean $\mu$ is equal to the sum of $\beta_0$ (the intercept) and the product of $\beta_1$ and speech rate ($\beta_1 \cdot \text{sr}$). The formula of $\mu$ is regression equation of the model.

The regression model estimates the parameters in the mathematical formulae: the parameters to be estimated in regression models are usually represented with Greek letters (hence why we adopted this notation for the linear equation). The regression model in the formulae above has to estimate the following three parameters:

-   The *regression coefficients* $\beta_0$ and $\beta_1$.

-   The standard deviation of the Gaussian distribution, $\sigma$.

$\beta_0$ and $\beta_1$ are called the **regression coefficients** because they are coefficients of the regression equation. In maths, a coefficient is simply a constant value that multiplies a "basis" in the equation, like the variable $x$. In the regression equation of the model, $\beta_1$ is a multiplier of the variable $x$, but what about $\beta_0$? Well, it is implied that $\beta_0$ is a multiplier of the constant basis `1`, because $\beta_0 \cdot 1 = \beta_0$. Knowing this should now reveal the reason behind the strange formula that R uses in Gaussian models like the ones we fitted in @sec-fit-model: the `1` in the formula stands for the constant basis of the intercept, meaning that the model estimates the coefficient of the intercept, $\beta_0$. Gaussian models without predictors are in fact also called intercept-only regression models, because only an intercept is estimated. There is no slope in the model because there is not variable $x$ to multiply the slope with.

Going back to our regression model of vowel duration and speech rate, we can rewrite the model formula to make the constant basis `1` explicit, thus:

$$
\begin{align}
vdur & \sim Gaussian(\mu, \sigma)\\
\mu & = \beta_0 \cdot 1 + \beta_1 \cdot sr\\
\end{align}
$$

To instruct R to model vowel duration as a function of the numeric predictor speech rate you simply *add* it to the `1` we have used in the right-hand side of the tilde in @sec-fit-model (i.e. `v1_duration ~ 1`): so `v1_duration ~ 1 + speech_rate`. The R formula is based on the bases you multiply the coefficients with in the mathematical formula: $1$ and $sr$. In R parlance, the `1` and `sr` in the R formula are called predictor terms, or terms for short. While the predictor $sr$ can take different values, the $1$ is constant so it is also called the **constant term**, or the **intercept term** (because it is the basis of the intercept $\beta_0$). In the R formula, you don't explicitly include the coefficients $\beta_0$ and $\beta_1$, just the bases. Put all this together and you get the `1 + speech_rate` part of the formula. There is more: in R, since the $1$ is a constant, you can omit it! So `v1_duration ~ 1 + speech_rate` can also be written as `v1_duration ~ speech_rate`. They are equivalent.

That was probably a lot! But now that we have clarified how the R formula is set up, we can proceed and fit the model. Here is the full code to fit a Gaussian regression model of vowel duration with brms.

```{r}
#| label: vow-bm
#| eval: false

library(brms)

vow_bm <- brm(
  # `1 +` can be omitted.
  v1_duration ~ 1 + speech_rate,
  # v1_duration ~ speech rate,
  family = gaussian,
  data = ita_egg_clean
)
```

```{r}
#| label: vow-bm-run
#| include: false

library(brms)

vow_bm <- brm(
  # `1 +` can be omitted.
  v1_duration ~ 1 + speech_rate,
  # v1_duration ~ speech rate,
  family = gaussian,
  data = ita_egg_clean,
  cores = 4,
  seed = 20912,
  # see below for an explanation of the file argument
  file = "cache/ch-regression-vow_bm"
)
```

::: {.callout-important collapse="true"}
### R Note: The rethinking package

<!--# TODO: rethinking package box -->

XXX
:::

## Interpret the model summary

As we has seen in @sec-fit-model, to obtain a summary of the model, we use the `summary()` function.

```{r}
#| label: vow-bm-summary

summary(vow_bm)
```

Let's focus on the `Regression Coefficients` table of the summary. It should now be clear why in the summary of the model in @sec-fit-model, the summaries for the mean $\mu$ (i.e. $\beta_0$) were in the regression coefficients table. The table of the regression model we just fit has two coefficients. To understand what they are, just remember the equation of the line and the model formula above.

-   `Intercept` is $\beta_0$: this is the mean vowel duration, **when speech rate is 0**.

-   `speech_rate` is $\beta_1$: this is the change in vowel duration **for each unit increase of speech rate**.

This should make sense, if you understand the equation of a line: $y = \beta_0 + \beta_1 x$. Remember, the intercept $\beta_0$ is the $y$ value when $x$ is 0. In our regression model, $y$ is vowel duration and $x$ is speech rate. So the `Intercept` is the mean vowel duration when speech rate is 0. Recall that the `Estimate` and `Est.Error` column are simply the **mean and standard deviation of the posterior probability distributions** of the estimate of `Intercept` and `speech_rate` respectively. In this model we just have two coefficients instead of one. Looking at the 95% Credible Intervals (CrIs), we can say that based on the model and data:

-   The mean vowel duration, when speech rate is 0 syl/s, is between 192 and 205 ms, at 95% confidence.

-   We can be 95% confident that, for each unit increase of speech rate (i.e. for each increase of one syllable per second), the duration of the vowel decreases by 20.5-23 ms.

To answer our research question (what is the relationship between vowel duration and speech rate?) we can say that with increasing speech rate, vowel duration decreases. We can be more precise than that and say that for each increase of one syllable per second, the vowel becomes 20.5 to 23 ms shorter, at 95% confidence (that is our 95% CrI).

To see what the posterior probability densities of $\beta_0$, $\beta_1$ and $\sigma$ look like, you can quickly plot them with the `plot()` function, as we did in @sec-fit-model. There is also another way: we can use the `mcmc_dens()` function from the [bayesplot](https://mc-stan.org/bayesplot/) package (why it's `mcmc_dens()` will become clear in @sec-regression-draws). By default the function plots the posterior densities of all parameters in the model, plus other internal parameters that we usually don't care about. We can conveniently specify which parameters to plot with the `pars` argument, which takes a character vector. The names of the parameters for the regression coefficients are slightly different than what you see in the summary: `b_Intercept` and `b_speech_rate`. These are just the names you see in the summary, with a prefixed `b_`. The `b_` stands for beta coefficient, which makes sense, since these are the $\beta_0$ and $\beta_1$ coefficients. @fig-vow-bm shows the output of the `mcmc_dens()` function.

```{r}
#| label: fig-vow-bm
#| fig-cap: "Posterior density plots of a regression model fitted to vowel duration."
#| fig-asp: 0.4

library(bayesplot)

mcmc_dens(vow_bm, pars = c("b_Intercept", "b_speech_rate", "sigma"))
```

These are the results of the regression model: the full posterior probability distributions of the three parameters $\beta_0$, $\beta_1$, $\sigma$. The posteriors can be described, as with any other probability distribution, by the values of their parameters. It is common to use the mean and standard deviation, the parameters of the Gaussian distribution. This is independent from the fact that we fitted a Gaussian distribution: posterior distributions tend to be bell-shaped, i.e. Gaussian. This is why the `Regression Coefficients` table of the summary reports mean and SD, i.e. `Estimate` and `Est.Err`, as mentioned earlier.

You should always also plot the model predictions, i.e. the predicted values of vowel duration based on the model predictors (here just `speech_rate`). You will learn more advanced methods later on, but for now you can use `conditional_effects()` from the brms package.

```{r}
#| label: fig-vow-bm-cond
#| fig-cap: "Posterior predictions of vowel duration based on speech rate from a regression model."

conditional_effects(vow_bm, effects = "speech_rate")
```

If you wish to include the raw data in the plot, you can wrap `conditional_effects()` in `plot()` and specify `points = TRUE`. Any argument that needs to be passed to `geom_point()` (these are all ggplot2 plots!) can be specified in a list as the argument `point_args`. Here we are making the points transparent.

```{r}
#| label: fig-vow-bm-cond-1
#| fig-cap: "Posterior predictions of vowel duration based on speech rate from a regression model (repr.)."

plot(
  conditional_effects(vow_bm, effects = "speech_rate"),
  points = TRUE,
  point_args = list(alpha = 0.1)
)
```

This plot looks basically the same as @fig-vow-rate-lm. Indeed, in @fig-vow-rate-lm we used `geom_smooth()` to add a regression line from a regression model. A warning told us that this formula was used: `y ~ x`. In the context of that plot, that means the smooth function fitted a regression model with speech rate as `x` and vowel duration as `y`. This is because the aesthetics are exactly `aes(x = speech_rate, y = v1_duration)` (we didn't write the `x =` and `y =` because they are implied). So `geom_smooth()` has fitted exactly the same model we have fitted with brms. It might look trivial to fit a full model when you can just look at the regression line of `geom_smooth()`. This is not the case for two reasons: first, you just see a regression line, but you don't know what the posterior distributions of the parameters are; second, with more complex scenarios, `geom_smooth()` falls short and can only produce regression lines based on very simple formulae like `y ~ x`.[^ch-regression-1]

[^ch-regression-1]: Technically, `geom_smooth()` uses `lm()` under the hood. This is a base R function that fits regression models using [maximum likelihood estimation](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) (MLE). This way of estimating regression coefficients is common in frequentist approaches to regression modelling and we will not treat it here. If you are interested about `lm()` and MLE, you can learn about these in @winter2020.

## Reporting

You have seen an example of reporting in @sec-fit-model. We can use that as a template for reporting a regression model, by reworking a few parts and adding information related to the numeric predictor in the regression. You could report the vowel duration regression model like so:

> We fitted a Bayesian regression model using the brms package [@burkner2017] in R [@rcoreteam2025]. We used a Gaussian distribution for the outcome variable, vowel duration (in milliseconds). We included speech rate (measured as syllables per second) as the regression predictor.
>
> Based on the model results, there is a 95% probability that the mean vowel duration, when speech rate is 0, is between `{r} round(brms::fixef(vow_bm)[1, 3])` and `{r} round(brms::fixef(vow_bm)[1, 4])` ms (mean = `{r} round(brms::fixef(vow_bm)[1, 1])`, SD = `{r} round(brms::fixef(vow_bm)[1, 2])`). For each unit increase of speech rate (i.e. for each one syllable per second added), vowel duration decreases by `{r} -round(brms::fixef(vow_bm)[2, 4])` to `{r} -round(brms::fixef(vow_bm)[2, 3])` ms (mean = `{r} round(brms::fixef(vow_bm)[2, 1])`, SD = `{r} round(brms::fixef(vow_bm)[2, 2])`). The residual standard deviation is between `{r} round(brms::posterior_summary(vow_bm)["sigma", "Q2.5"])` and `{r} round(brms::posterior_summary(vow_bm)["sigma", "Q97.5"])` ms (mean = `{r} round(brms::posterior_summary(vow_bm)["sigma", "Estimate"])`, SD = `{r} round(brms::posterior_summary(vow_bm)["sigma", "Est.Error"])`).

Note the wording of the speech rate coefficient: "vowel duration decreases by `{r} -round(brms::fixef(vow_bm)[2, 4])` to `{r} -round(brms::fixef(vow_bm)[2, 3])` ms". The speech rate coefficient 95% CrI is fully negative (i.e. both lower and upper limit are negative) so we can say that vowel duration *decreases*. Furthermore, since we say "decreases" then we should report the CrI limits as positive numbers. Think about it: we say "decrease X by 2" to mean "X - 2", rather than "decrease X by -2". Finally, given we flipped the signs of the CrI limits, it is clearer to write "`{r} -round(brms::fixef(vow_bm)[2, 4])` to `{r} -round(brms::fixef(vow_bm)[2, 3])` ms", rather than the other way round as you would if you reported the interval as is: 95% CrI \[`{r} round(brms::fixef(vow_bm)[2, 3])`, `{r} round(brms::fixef(vow_bm)[2, 4])`\].

Another point to note is that in the reporting style I am using in this book, we place more emphasis on the posterior CrI than on the posterior mean and SD. So the CrI is in the main text, while mean and SD are between parentheses. Other researchers might in fact do it the other way round. Whatever you decide to do, be consistent. Finally, it is unusual to report the coefficients of $\sigma$: I have done it here for completeness, since it doesn't hurt to do so.

## What's next

In this chapter you have learned the very basics of Bayesian regression models. As mentioned above, regression models with brms are very flexible and you can easily fit very complex models with a variety of distribution families (for a list of available families, see `?brmsfamily`; you can even define your own distributions!). The perk of using brms is that you can just learn the basics of one package and one approach and use it to fit a large variety of regression models. This is different from the standard frequentist approach, where different models require different packages or functions, with their different syntax and quirks. In the following weeks, you will build your understanding of Bayesian regression models, which will enable you to approach even the most complex models! However, due to time limits you won't learn everything there is to learn in this course. Developing conceptual and practical skills in quantitative methods is a long-term process and unfortunately one semester will not be enough. So be prepared to continue your learning journey for years to come!

## Summary

::: {.callout-note appearance="simple"}
-   Gaussian regression models have the following mathematical form:

$$
\begin{align}
y & \sim Gaussian(\mu, \sigma)\\
\mu & = \beta_0 + \beta_1 x\\
\end{align}
$$

-   A regression model estimates an intercept $\beta_0$ and a slope $\beta_1$ from the data ($x$ and $y$).

-   Regression models in brms are fit with the R formula `y ~ 1 + x`. We can omit the constant/intercept term: `y ~ x`.

-   The intercept $\beta_0$ is the mean $y$ when $x$ is `0` zero.

-   The slope $\beta_1$ is the change in $y$ for every unit increase of $x$.
:::
