# Regression models: categorical predictors {#sec-regression-cat}

![](https://img.shields.io/badge/Area-R-green)

In @sec-regression you learned how to fit regression models of the following form in R using the brms package.

$$
\begin{align}
y & \sim Gaussian(\mu, \sigma)\\
\mu & = \beta_0 + \beta_1 \cdot x\\
\end{align}
$$

In these models, $x$ was a numeric predictor, like speech rate. Numeric predictors are not the only type of predictors that a regression model can handle. Regression predictors can also be categorical: gender, age group, place of articulation, mono- vs bi-lingual, etc. However, regression model cannot handle categorical predictors directly: think about it, what would it mean to multiply $\beta_1$ by "female" or by "old". Categorical predictors have to be re-coded as numbers.

In this chapter we will revisit the MALD reaction times (RTs) data from @sec-fit-model, this time modelling RTs depending on the lexical status of the target work (real vs nonce word). You will learn about two ways of coding categorical predictors: treatment contrasts (the default type in most implementations of regression models) and indexing.

## Revisiting reaction times

Let's read the MALD data [@tucker2019].

```{r}
#| label: mald

library(tidyverse)

mald <- readRDS("data/tucker2019/mald_1_1.rds")
mald
```

The relevant columns are `RT` with the RTs in milliseconds and `IsWord,` which tells if the target word is a real English word (`TRUE`) or not (`FALSE`). @fig-mald-dens shows the density plot of RTs, grouped by whether the target word is real or not. We can notice that the distribution of RTs with nonce (non-real) words is somewhat shifted towards higher RTs, indicating that more time is needed to process nonce words than real words.

```{r}
#| label: fig-mald-dens
#| fig-cap: "Density plot of reaction times from the MALD data [@tucker2019]."

# Set the light theme for plots
theme_set(theme_light())

mald |> 
  ggplot(aes(RT, fill = IsWord)) +
  geom_density(alpha = 0.8) +
  scale_fill_brewer(palette = "Dark2")
```

You might also notice that the "tails" of the distributions (the left and right sides) are not symmetric: the right tail is heavier that the left tail. This is a very common characteristics of RT values and of any variable that can only be positive (like phonetic durations). These variables are "bounded" to only positive numbers. You will learn later on that the values in these variables are generated by a log-normal distribution, rather than by a Gaussian distribution (which is "unbounded"). For the time being though, we will model the data as if they were generated by a Gaussian distribution, for pedagogical reasons.

```{r}
#| label: fig-mald-jit
#| fig-cap: "Jitter and violin plot of reactions times for real and nonce words."

mald |>
  ggplot(aes(IsWord, RT, fill = IsWord)) +
  geom_jitter(alpha = 0.05, width = 0.1) +
  geom_violin(width = 0.1) +
  scale_fill_brewer(palette = "Dark2")
```

```{r}
#| label: mald-summ
mald |> 
  group_by(IsWord) |> 
  summarise(
    round(mean(RT)), median(RT), round(sd(RT))
  )
```

$$
\begin{align}
y_i & \sim Gaussian(\mu_i, \sigma)\\
\mu_i & = \beta_0 + \beta_1 \cdot w_i\\
\end{align}
$$

| `IsWord`       | `w` |
|----------------|:---:|
| IsWord = TRUE  |  0  |
| IsWord = FALSE |  1  |

: Treatment contrasts coding of the categorical predictor `IsWord`. {#tbl-treat}

$$
\begin{align}
\mu_i & = \beta_0 + \beta_1 \cdot w_i\\
\mu_{\text{T}} & = \beta_0 + \beta_1 \cdot 0 = \beta_0\\
\mu_{\text{F}} & = \beta_0 + \beta_1 \cdot 1 = \beta_0 + \beta_1
\end{align}
$$

If $\beta_0$ is the *mean* RT when `IsWord` is TRUE, what is $\beta_1$? Simple.

$$
\begin{align}
\beta_1 & = \mu_\text{F} - \mu_\text{T}\\
& = (\beta_0 + \beta_1) - \beta_0
\end{align}
$$

$\beta_0$ is the *difference* between the mean RT when `IsWord` is TRUE and the mean RT when `IsWord` is FALSE.

```{r}
#| label: rt-bm-1
library(brms)

rt_bm_1 <- brm(
  RT ~ IsWord,
  family = gaussian,
  data = mald,
  seed = 6725,
  file = "cache/ch-regression-cat-rt_bm_1"
)
```

```{r}
#| label: rt-bm-1-summ
summary(rt_bm_1)
```

## Indexing of categorical predictors

$$
\begin{align}
y_i & \sim Gaussian(\mu_i, \sigma)\\
\mu_i & = \beta_{\text{W}[i]}\\
\end{align}
$$

```{r}
#| label: rt-bm-2

rt_bm_2 <- brm(
  RT ~ 0 + IsWord,
  family = gaussian,
  data = mald,
  seed = 6725,
  file = "cache/ch-regression-cat-rt_bm_2"
)
```

```{r}
#| label: rt-bm-2-summ
summary(rt_bm_2)
```

## More than two levels

```{r}
#| label: eu-vot

eu_vot <- read_csv("data/egurtzegi2020/eu_vot.csv")
eu_vot
```

```{r}
#| label: eu-vot-three

eu_vot <- eu_vot |> 
  mutate(
    phonation = case_when(
      phone %in% c("p", "t", "k") ~ "voiceless",
      phone %in% c("b", "d", "g") ~ "voiced",
      phone %in% c("ph", "th", "kh") ~ "aspirated"
    ),
    VOT = VOT * 1000
  )

```

```{r}
#| label: fig-eu-vot-dens

eu_vot |> 
  drop_na(phonation) |> 
  ggplot(aes(VOT, fill = phonation)) +
  geom_density(alpha = 0.5)

```

```{r}
#| label: fig-eu-vot-jit

eu_vot |> 
  drop_na(phonation) |> 
  ggplot(aes(phonation, VOT)) +
  geom_jitter(alpha = 0.5, width = 0.2)

```

```{r}
#| label: vot_bm

vot_bm <- brm(
  VOT ~ 0 + phonation,
  family = gaussian,
  data = eu_vot,
  seed = 6725,
  file = "cache/ch-regression-cat-vot_bm"
)

```

`Warning: Rows containing NAs were excluded from the model.`

```{r}
#| label: vot-bm-summ
summary(vot_bm)
```
