# Quantitative data analysis {#sec-quantitative}

```{r}
#| label: setup
#| include: false

library(webexercises)
```

![](https://img.shields.io/badge/Area-Statistics-red)

![](img/res-process-data-ana.png)

**Data analysis** is anything that relates to analysing data, whether you collected it yourself or you used pre-existing data.

There are two main approaches to data analysis:

-   **Quantitative data analysis** is about learning from measured data. Data can be operationalised in many different ways and these determine the type of analyses you can apply.

-   **Qualitative data analysis** is about learning from the features and characteristics of the data.

![](img/data-quant-qual.png)

Note that while it is common to talk about "quantitative vs qualitative *data*" in fact in most cases data can be conceived as both quantitative *and* qualitative. It is really how we approach the data that can be quantitative and/or qualitative. Moreover, these two approaches to data analysis are not necessarily opposite to each other and there are some aspects of each in each other. This will become clearer at the end of the course this textbook is written for.

This textbook focuses on quantitative data analysis. The rest of this chapter introduces fundamental concepts of quantitative methods.

## Quantitative data analysis

![](img/data-quant.png)

Quantitative analyses are usually comprised of three parts (these are not strictly distinct and the boundaries are sometimes blurred):

-   Summarise data with summary measures.

-   Visualise data with plots.

-   Model data with statistical models.

**Summary measures** are numbers that represent certain properties of the data: common summary measures are the mean and the standard deviation. You will have frequently seen these in published paper, either in text or as a table. You will learn about summary measures in @sec-summaries.

**Plots**, or graphs, are another common way to summarise data but they are based on visual representation rather than single numbers. As the saying goes, "[a picture is worth a thousand words](https://en.wikipedia.org/wiki/A_picture_is_worth_a_thousand_words)". The aim of plots is to make explicit certain patterns in the data. Choosing and designing plots that are effective and captivating is more of an art and you will learn the basics and heuristics of good (and bad plots) in @sec-viz.

**Statistical models** are mathematical representations of patterns and relationship in data. Statistical modelling is a powerful tool to learn from the data or to assess research hypotheses. This textbook introduces you to a specific type of statistical models: regression models. These are highly flexible model that can be used with a variety of data types. You will start learning about statistical models in @sec-reg-intro.

## Numbers have no meaning

As mentioned earlier, both qualitative and quantitative approaches are valid and necessary to improve our understanding of things. Moreover, even a very complex quantitative analysis will always contain some qualitative aspects.

::: {.callout-important appearance="simple"}
The numbers have no way of speaking for themselves. We speak for them. We imbue them with meaning.

— Nate Silver, *The Signal and the Noise*
:::

There's a lot of wisdom in that quote. Numbers do not mean anything by themselves. We need to interpret numbers, "imbue them with meaning", based on many aspects of research and beyond, including our own identity and positionality [@jafar2018; @darwin2020].

## Inference process

![](img/bro.png){fig-align="center" width="250"}

Imbuing numbers with meaning is a good characterisation of the **inference process**.

Here is how it works. We have a question about something. Let's imagine that this something is the population of British Sign Language signers. We want to know whether the cultural background of the BSL signers is linked to different pragmatic uses of the sign for BROTHER. But we *can't survey the entire population* of BSL signers.[^ch-quantitative-1]

[^ch-quantitative-1]: NOTE: *Population* can be a set of anything, not just a specific group of people. For example, the words in a dictionary can be a "population"; or the antipassive constructions of Austronesian languages...

So instead of surveying *all* BSL users, we take a **sample** from the BSL population. The sample is our data (the product of our study or observation). Now, how do we go from data/observation to answering our question about the use of BROTHER? We can use the inference process!

::: callout-note
#### Inference process

**Inference** is the process of understanding something about a population based on the sample (aka the data) taken from that population.
:::

The figure below is a schematic representation of the inference process.

![](img/inference.png)

XXX

However, inference, despite being based on data, does not guarantee that the answers to our questions are right or even that they are true. In fact, any observation we make comes with a certain degree of **uncertainty and variability**.

::: callout-note
### Quiz 1

```{r}
#| label: quiz-1
#| results: asis
#| echo: false

cat("**True or false?**", "\n\n")
cat("a. Inference is not needed if you gather data from the entire population.", torf(TRUE), "\n\n")
cat("b. Population refers only to human participants.", torf(FALSE), "\n\n")
cat("c. A sample is *always* a truthful representation fo the population.", torf(FALSE), "\n\n")
cat("d. You can collect the same sample multiple times.", torf(FALSE))
```
:::

::: {.callout-important collapse="true"}
#### Extra

-   Check out this article: <https://www.scientificamerican.com/article/if-you-say-science-is-right-youre-wrong/>.
-   Find out about Popper's view of falsification and fallibilism.
-   Learn more about uncertainty and subjectivity in research: @vasishth2021, @gelman2017.
:::

## Uncertainty and variability

![](img/pliny.jpg)

[Pliny the Elder](https://en.wikipedia.org/wiki/Pliny_the_Elder) was a Roman philosopher who died in the Vesuvius eruption in 79 CE. He certainly did not expect to die then. Leaving dark irony aside, as researchers we have to deal with uncertainty and variability:

-   **Uncertainty** is about each observation of a phenomenon due to measurement error or because we cannot directly measure what we want to measure.

-   **Variability** is found among different observations of the same phenomenon due natural fluctuations and measurement error.

So uncertainty is a feature of each mesurement, while variability occurs between different measurements. Together, uncertainty and variability render the inference process more complex and can interfere with its outcomes.

The following picture is a reconstruction of what Galileo Galilei saw when he pointed one of his first telescopes towards Saturn, based on his 1610 sketch: a blurry circle flanked by two smaller blurry circles.

![](img/uncertainty.png)

Only six years later, telescopes were much better and Galileo could correctly identify that the flaking circles were not spheres orbiting around Saturn, but rings.

The moral of the story is that at any point in history we are like Galileo in at least some of our research: we might be close to understanding something but not quite there yet. So what do we do with such uncertainty and variability? We can use statistics to quantify them! **Statistics is a tool that helps us quantifying uncertainty and controlling for variability.** But what is statistics exacly?

## What is statistics?

Statistics is a **tool**. But what does it do? There are at least four ways of looking at statistics as a tool.

-   Statistics is the **science** concerned with developing and studying methods for collecting, analyzing, interpreting and presenting empirical data. (From [UCI Department of Statistics](https://www.stat.uci.edu/what-is-statistics/))

-   Statistics is the **technology** of extracting information, illumination and understanding from data, often in the face of uncertainty. (From the [British Academy](https://www.thebritishacademy.ac.uk/blog/what-is-statistics/))

-   Statistics is a **mathematical and conceptual** discipline that focuses on the relation between data and hypotheses. (From the [Standford Encyclopedia of Philosophy](https://plato.stanford.edu/entries/statistics/))

-   Statistics is the **art** of applying the science of scientific methods. (From [ORI Results](https://www.oriresults.com/articles/blog-posts/the-art-of-statistics/), [Nature](https://www.nature.com/articles/d41586-019-00898-0))

To quote a statistician:

> *Statistic is both a science and an art*.
>
> It is a *science* in that its methods are basically systematic and have general application and an *art* in that their successful application depends, to a considerable degree, on the skill and special experience of the statistician, and on his knowledge of the field of application.

—L. H. C. Tippett

::: {.callout-important collapse="true"}
#### Extra

Check out the etymology of *statistics* here: <https://en.wiktionary.org/wiki/statistics#Etymology_1>.
:::

## What statistics is NOT

Statistics is a many things, but it is also *not* a lot of things.

-   Statistics is **not maths**, but it is informed by maths.

-   Statistics is **not about hard truths** not how to seek the truth.

-   Statistics is **not a purely objective** endeavour. In fact there are a *lot* of subjective aspects to statistics (see below).

-   Statistics is **not a substitute** of common sense and expert knowledge.

-   Statistics is **not just** about $p$-values and significance testing.

As Gollum would put it, *all that glisters is not gold*.

![](img/gollum-statistician.png){fig-align="center" width="300"}

## Many Analysts, One Data Set: subjectivity exposed

![](img/red-card.jpg){fig-align="center" width="250"}

In [Silberzahn et al 2018](https://doi.org/10.1177/2515245917747646), a group of researchers asked 29 independent analysis teams to answer the following question based on provided data: **Is there a link between player skin tone and number of red cards in soccer?**

Crucially,

-   **69%** of the teams reported an effect of player skin tone, and **31%** did not.

-   In total, the 29 teams came up with **21 unique** types of statistical analysis.

These results clearly show how subjective statistics is and how even a straightforward question can lead to a multitude of answers.

To put it in Silberzah et al's words:

> The observed results from analyzing a complex data set can be highly contingent on **justifiable**, but **subjective**, analytic decisions.

This is why you should always be somewhat **sceptical of the results of any single study**: you never know what results might have been found if another research team did the study. This is a reason for why replicating research is very important.

<!-- TODO: add link to repro/repli -->

[Coretta et al 2023](https://doi.org/10.1177/25152459231162567) tried something similar, but in the context of the speech sciences: they asked 30 independent analysis teams (84 signed up, 46 submitted an analysis, 30 submitted usable analyses) to answer the question **Do speakers acoustically modify utterances to signal atypical word combinations?**

Incredibly, the 30 teams submitted:

-   **109** individual analyses. A bit more than 3 analyses per team!
-   **52** unique measurement specifications and **47** unique model specifications.

> Nine teams out of the thirty (30%) reported to have found at least one statistically reliable effect (based on the inferential criteria they specified). Of the 170 critical model coefficients, 37 were claimed to show a statistically reliable effect (21.8%).

—Coretta et al, 2023

![](img/forking-paths.png){fig-align="center" width="300"}

## The "New Statistics"

The Silberzahn et al and Coretta et al studies are just the tip of the iceberg. We are currently facing a "research crisis".

<!-- Add link to research crises -->

[Cumming 2014](https://doi.org/10.1177%2F0956797613504966) proposes a new approach to statistics, which he calls the "New Statistics", in response to the research crisis.

The New Statistics mainly addresses **three problems**:

-   Published research is a biased selection of all (existing and possible) research.

-   Data analysis and reporting are often selective and biased.

-   In many research fields, studies are rarely replicated, so false conclusions persist.

To help solve those problems, it proposes **these solutions** (among others):

-   Promoting **research integrity**.

-   Shifting away from statistical significance to **estimation**.

-   Building a **cumulative** quantitative discipline.

## The Bayesian New Statistics

[Kurschke and Liddell 2018](https://doi.org/10.3758/s13423-016-1221-4) revisit the New Statistics and make a further proposal: to adopt the historically older but only recently popularised approach of Bayesian statistics. They call this the Bayesian New Statistics.

The classical approach to statistics is the **frequentist method**, based on work by Fisher, and Neyman and Pearson. Frequentist statistics is based on rejecting the "null hypothesis" (i.e. the hypothesis that there is no difference between groups) using *p*-values.

**Bayesian statistics** provides researchers with more appropriate and more robust ways to answer research questions, by reallocation of belief/credibility across possibilities.

You will learn more about the frequentist and the Bayesian approaches in @sec-inference.
