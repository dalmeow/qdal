# Probability distributions {#sec-probability}

![](https://img.shields.io/badge/Area-Statistics-red)

## Probabilities

Probability is the study of chance and uncertainty. It provides a systematic way to describe and reason about events whose outcomes cannot be predicted with certainty. In everyday life, probability is used to talk about situations ranging from rolling dice and drawing cards to forecasting the weather or assessing risks. A probability is expressed as a number between 0 and 1, where 0 means the event is impossible, 1 means it is certain, and values in between reflect varying degrees of likelihood. Thinking in terms of probability allows us to quantify uncertainty and to make informed statements about how likely different outcomes are, even when we cannot predict exactly what will happen.

The rules of probability ensure that these numbers behave consistently. The **non-negativity rule** states that no probability can be less than 0. The **normalization rule** requires that the probability of all possible outcomes of a situation must add up to exactly 1, which guarantees that something in the set of possible outcomes will happen. The **addition rule** tells us that if two events cannot both occur at the same time—such as rolling a 3 or rolling a 5 on a single die throw—the probability of either happening is the sum of their individual probabilities. The **multiplication rule** applies when two events are independent, meaning the outcome of one does not affect the other—for instance, tossing a coin and rolling a die. In that case, the probability of both occurring together is the product of their probabilities. These rules provide the logical foundation for reasoning about chance and will serve as the basis for describing probability distributions, which organize and model probabilities across a whole set of possible outcomes.

::: callout-note
### Quiz 1

```{r}
#| label: quiz-1
#| results: asis
#| echo: false

cat("**True or false?**", "\n\n")
cat("a. A certain event is an event that has a probability equal to or greater than 1.", torf(FALSE), "\n\n")
cat("b. An event that has probability of 0 is an impossible event.", torf(TRUE), "\n\n")
cat("c. Probabilities are expressed with a number between 0 and 1 (inclusive).", torf(TRUE), "\n\n")
cat("d. When one event cannot occur if another does occur, these are called equally likely events.", torf(FALSE))
```
:::

## Probability distributions

A probability distribution is a way of describing how probabilities are assigned to all possible outcomes of a random process. Instead of focusing on the chance of a single event, a distribution gives the full picture: it tells us the likelihood of every possible value a random variable can take. For example, when rolling a fair six-sided die, the probability distribution assigns a probability of $1/6$ to each face, reflecting that all outcomes are equally likely. In other cases, probabilities may not be spread evenly, as with a biased coin or the distribution of heights in a population. By summarizing the likelihood of all outcomes at once, probability distributions allow us to see patterns of chance in a clear and structured way.

There are two broad types of probability distributions: **discrete** and **continuous**. Discrete distributions apply when the set of possible outcomes is countable, such as the result of a dice roll, the number of cars passing a junction in an hour, or the number of students present in a classroom. Here, probabilities are assigned to distinct values, and the total across all possible outcomes must equal 1. Continuous distributions, on the other hand, are used when outcomes can take on any value within a range, such as weight, temperature, or time. In these cases, probabilities are described by smooth curves rather than discrete points, and instead of assigning probability to individual values, we consider intervals: for example, the probability that a person’s height lies between 160 cm and 170 cm.

Several well-known distributions serve as fundamental building blocks in probability and statistics. Among discrete distributions, the binomial distribution describes the number of successes in a fixed number of independent trials (like accuracy data from a behavioural task), while the Poisson distribution is used for counting events that occur randomly over time or space (such as number of relatives sentences in a corpus). In the continuous case, the **Gaussian distribution**---also called the "normal" distribution and nicknamed the “bell curve"---has many useful mathematical properties and it features prominently in any statistical textbook. Other continuous distributions are, for example, the beta distribution, for continuous variables bounded between 0 and 1, and the uniform distribution, which distributed probabilities equally across the entire range of real numbers.

Probability distributions are more than just mathematical descriptions---they provide tools for making sense of variation and uncertainty in the world. They allow us to calculate probabilities for complex events, to compare different random processes, and to build models that reflect real-world randomness. Once the distribution of a random variable is known, we can derive useful summaries such as averages, variability, and the likelihood of extreme outcomes. In this way, probability distributions bridge the abstract rules of probability with the practical task of describing how chance operates across a whole set of possibilities.

## The Gaussian distribution

In the previous section, we have seen that you can visualise probability distributions by plotting the values of the probability function applied to sampled values. For discrete variables, the probability mass function is used while the probability density function is used for continuous variables. Visualising probability distributions is more practical than listing all the possible values and their probability (especially with continuous variables—since they are continuous there is an infinite number of values!). Another convenient way to express probability distributions is by specifying the values of set of parameters, which can reconstruct the entire distribution. Different **probability distribution families** have a different number of parameters and different parameters. A probability family is an abstraction of specific probability distributions (i.e. probability distributions of observed values).

A convenient probability distribution family is the **Gaussian** \[ˈgaʊsɪən\] **probability distribution**. The Gaussian distribution is a continuous probability distribution and it has two parameters:

-   The **mean**, represented with the Greek letter $\mu$ \[mjuː\]. This parameter is the probability's central tendency. Values around the mean have higher probability than values further away from the mean.

-   The **standard deviation**, represented with the Greek letter $\sigma$ \[ˈsɪgmə\]. This parameter is the probability's dispersion around the mean. The higher $\sigma$ the greater the spread (i.e. the dispersion) of values around the mean.

In statistical notation, we write the Gaussian distribution family like this:

$$
Gaussian(\mu, \sigma)
$$

Specific types of Gaussian distributions will have specific values for the parameters $\mu$ and $\sigma$: for example $Gaussian(0, 1)$, $Gaussian(50, 32)$, $Gaussian(2.5, 6.25)$, and so on. All of these specific probability distributions belong to the Gaussian family.

::: callout-warning
### Exercise

-   Go to [Seeing Theory](https://seeing-theory.brown.edu/probability-distributions/index.html#section2), Chapter 3 Probability distributions.

-   Select "Continuous".

-   In the drop-down menu, select "Normal". This is another term for Gaussian.

-   Scroll down and change the mean $\mu$. What happens to the probability density (shown on the right)?

-   Change the standard deviation $\sigma$. What happens to the probability density?
:::

## Intervals

