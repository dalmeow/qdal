# Probability distributions {#sec-probability}

![](https://img.shields.io/badge/Area-Statistics-red)

## Inference: From sample to population

```{r}
#| label: setup
#| include: false

library(tidyverse)
library(webexercises)
library(glue)
```

```{r}
#| label: mald

mald <- readRDS("data/tucker2019/mald_1_1.rds")

```

```{r}
#| label: mald-rt

mald |> 
  ggplot(aes(RT)) +
  geom_density(fill = "purple", alpha = 0.5) +
  geom_rug(alpha = 0.1) +
  labs(x = "Reaction Times (ms)")

```

```{r}
#| label: mald-summ
mald |> 
  summarise(
    mean_RT = round(mean(RT)), sd_RT = round(sd(RT)), median_RT = round(median(RT))
  )
```

```{r}
#| label: rt-l

set.seed(9899)
rt_l <- list()
for (i in 1:10) {
  rt_l[i] <- list(rnorm(n = 20, mean = 1010, sd = 318))
}
rt_l[[1]]
```

```{r}
# TODO: make into table
cat("Mean:\n", round(unlist(lapply(rt_l, mean))), "\n")
cat("SD:\n", round(unlist(lapply(rt_l, sd))))
```

## Probabilities

::: callout-note
### Quiz 1

```{r}
#| label: quiz-1
#| results: asis
#| echo: false

cat("**True or false?**", "\n\n")
cat("a. A certain event is an event that has a probability equal to or greater than 1.", torf(FALSE), "\n\n")
cat("b. An event that has probability of 0 is an impossible event.", torf(TRUE), "\n\n")
cat("c. Probabilities are expressed with a number between 0 and 1 (inclusive).", torf(TRUE), "\n\n")
cat("d. When one event cannot occur if another does occur, these are called equally likely events.", torf(FALSE))
```
:::

## Probability distributions

## The Gaussian distribution

In the previous section, we have seen that you can visualise probability distributions by plotting the values of the probability function applied to sampled values. For discrete variables, the probability mass function is used while the probability density function is used for continuous variables. Visualising probability distributions is more practical than listing all the possible values and their probability (especially with continuous variables—since they are continuous there is an infinite number of values!). Another convenient way to express probability distributions is by specifying the values of set of parameters, which can reconstruct the entire distribution. Different **probability distribution families** have a different number of parameters and different parameters. A probability family is an abstraction of specific probability distributions (i.e. probability distributions of observed values).

A convenient probability distribution family is the **Gaussian** \[ˈgaʊsɪən\] **probability distribution**. The Gaussian distribution is a continuous probability distribution and it has two parameters:

-   The **mean**, represented with the Greek letter $\mu$ \[mjuː\]. This parameter is the probability's central tendency. Values around the mean have higher probability than values further away from the mean.

-   The **standard deviation**, represented with the Greek letter $\sigma$ \[ˈsɪgmə\]. This parameter is the probability's dispersion around the mean. The higher $\sigma$ the greater the spread (i.e. the dispersion) of values around the mean.

In statistical notation, we write the Gaussian distribution family like this:

$$
Gaussian(\mu, \sigma)
$$

Specific types of Gaussian distributions will have specific values for the parameters $\mu$ and $\sigma$: for example $Gaussian(0, 1)$, $Gaussian(50, 32)$, $Gaussian(2.5, 6.25)$, and so on. All of these specific probability distributions belong to the Gaussian family.

::: callout-warning
### Exercise

-   Go to [Seeing Theory](https://seeing-theory.brown.edu/probability-distributions/index.html#section2), Chapter 3 Probability distributions.

-   Select "Continuous".

-   In the drop-down menu, select "Normal". This is another term for Gaussian.

-   Scroll down and change the mean $\mu$. What happens to the probability density (shown on the right)?

-   Change the standard deviation $\sigma$. What happens to the probability density?
:::

## Intervals
