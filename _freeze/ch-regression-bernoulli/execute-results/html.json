{
  "hash": "c6d5a2332f7486a5c741fe79fb5e1bf9",
  "result": {
    "engine": "knitr",
    "markdown": "---\nauthor: [\"Stefano Coretta\", \"Elizabeth Pankratz\"]\n---\n\n# Binary outcomes {#sec-regression-bernoulli}\n\n![](https://img.shields.io/badge/Area-Statistics-red) ![](https://img.shields.io/badge/Area-R-green)\n\n\n\n**Binary outcome variables** are very common in linguistics. These are categorical variable that have **two levels**, e.g.:\n\n-   yes / no\n-   grammatical / ungrammatical\n-   Spanish / English\n-   direct object (*gave the girl the book*) / prepositional phrase (*gave the book to the girl*)\n-   correct / incorrect\n\nSo far you have been fitting regression models in which the outcome variable was numeric and continuous. However, a lot of studies use binary outcome variables and it thus important to learn how to deal with those. This is what this chapter is about.\n\nWhen modelling binary outcomes, what the researcher is usually interested in is the probability of obtaining one of the two levels. For example, in a lexical decision task one might want to know the probability that real words were recognised as such (in other words, we are interested in accuracy: incorrect or correct response). Let's say there is an 80% probability of responding correctly. So ($p()$ stands for \"probability of\"):\n\n-   $p(\\text{correct}) = 0.8$\n-   $p(\\text{incorrect}) = 1 - p(\\text{correct}) = 0.2$\n\nYou see that if you know the probability of one level (correct) you automatically know the probability of the other level, since there are only two levels and the total probability has to sum to 1. The distribution family for binary probabilities is the **Bernoulli family**. The Bernoulli family has only one parameter, $p$, which is the probability of obtaining one of the two levels (one can pick which level). With our lexical decision task example, we can write:\n\n$$\n\\begin{align}\nresp_{\\text{correct}} & \\sim Bernoulli(p) \\\\\np & = 0.8\n\\end{align}\n$$\n\nYou can read it as:\n\n> The probability of getting a correct response follows a Bernoulli distribution with $p$ = 0.8.\n\nIf you randomly sampled from $Bernoulli(0.8)$ you would get \"correct\" 80% of the times and \"incorrect\" 20% of the times. We can test this in R. In previous chapters we used the `rnorm()` function to generate random numbers from Gaussian distributions. R doesn't have an `rbern()` function, so we have to use the `rbinom()` function instead. The function generates random observations from a binomial distribution: the binomial distributions is a more general form of the Bernoulli distribution. It has two parameters, $n$ the number of trials and $p$ the \"success\" probability of each trial. If we code each level in the binary variable as 0 and 1, $p$ is the probability of getting 1 (that's why it is called the \"success\" probability).\n\n$$\nBinomial(n, p)\n$$\n\nThink of a coin: you flip it 10 times so $n = 10$ (ten trials). If this is a fair coin, then $p$ should be 0.5: 50% of the times you get head (1) and 50% of the times you get tail (0). The `rbinom()` function takes three arguments: `n` number of observations (maybe confusingly, not the number of trials), `size` the number of trials, and `p` the probability of success. The following code simulates 10 flips of a fair coin with `rbinom()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the seed for reproducibility\nset.seed(9182)\n\nrbinom(1, 10, 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 6\n```\n\n\n:::\n:::\n\n\nThe output is `6`, meaning 6 out of 10 flips had head (1). Note that the probability of success $p$ is the *mean* probability of success. In any one observation, you won't necessarily get 5 of 10 with $p = 0.5$, but if you take many 10-trial observations, then on average you should get pretty close to 0.5. Let's try this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the seed for reproducibility\nset.seed(9182)\n\nmean(rbinom(100, 10, 0.5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 5.08\n```\n\n\n:::\n:::\n\n\nHere we took 100 observations of 10 flips. On average, about 5 of 10 flips got head (it is not precisely 5, but very close).\n\nA Bernoulli distribution is simply a binomial distribution with a single trial. Imagine again a lexical decision task: each word presented to the participant is one trial and in each trial there is a probability $p$ of getting it right (correctly identifying the type of the word). We can thus use `rbinom()` with `size` set to 1. Let's get 25 observations of 1 trial each.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set the seed for reproducibility\nset.seed(9182)\n\nrbinom(25, 1, 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 1 0 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n```\n\n\n:::\n:::\n\n\nFor each trial, we get a `1` for correct or a `0` for incorrect. If you take the mean of the trials it should be very close to 0.8 (with those random observations, it is 0.84). Again, $p$ is the mean probability of success across trials.\n\nNow, what we are trying to do when modelling binary outcome variables is to estimate the probability $p$ from the data. But there is a catch: probabilities are bounded between 0 and 1 and regression models don't work with bounded variables out of the box! Bounded probabilities are transformed into an unbounded numeric variable. The following section explains how.\n\n## Probability and log-odds\n\nAs we have just learned probabilities are bounded between 0 and 1 but we need something that is not bounded because regression models don't work with bounded numeric variables. This is where the **logit function** comes in: the logit function (from \"*log*istic un*it*\") is a mathematical function that transforms probabilities into log-odds. @fig-p-log-odds shows the correspondence of probabilities (on the *y*-axis) and log-odds (on the *x*-axis), as marked by the black S-shaped line. Since probabilities can't be smaller than 0 and greater than 1, the black line slopes in either direction and it approaches 0 and 1 on the *y*-axis without ever reaching them (in mathematical terms, it's an *asymptotic* line). It is helpful to just memorise that probability 0.5 corresponds to log-odds 0.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\"}\ndots <- tibble(\n  p = seq(0.1, 0.9, by = 0.1),\n  log_odds = qlogis(p)\n)\n\np_log_odds <- tibble(\n  p = seq(0, 1, by = 0.001),\n  log_odds = qlogis(p)\n) %>%\n  ggplot(aes(log_odds, p)) +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\") +\n  geom_hline(yintercept = 0, colour = \"#8856a7\", linewidth = 1) +\n  geom_hline(yintercept = 1, colour = \"#8856a7\", linewidth = 1) +\n  geom_vline(xintercept = 0, alpha = 0.5) +\n  geom_line(linewidth = 2) +\n  # geom_point(data = dots, size = 4) +\n  geom_point(x = 0, y = 0.5, colour = \"#8856a7\", size = 4) +\n  annotate(\"text\", x = -4, y = 0.8, label = \"logit(p) = log-odds\") +\n  scale_x_continuous(breaks = seq(-6, 6, by = 1), minor_breaks = NULL, limits = c(-6, 6)) +\n  scale_y_continuous(breaks = seq(0, 1, by = 0.1), minor_breaks = NULL) +\n  labs(\n    x = \"Log-odds\",\n    y = \"Probability\"\n  )\np_log_odds\n```\n\n::: {.cell-output-display}\n![Correspondence between log-odds and probabilities](ch-regression-bernoulli_files/figure-html/fig-p-log-odds-1.png){#fig-p-log-odds width=672}\n:::\n:::\n\n\nWhen you fit a regression model with a binary outcome and a Bernoulli family, the estimates of the regression coefficients are in log-odds. To transform log-odds back into probability, one uses the **inverse logit** (also called logistic) **function**. The logit and inverse logit functions in R are applied with the `qlogis()` and `plogis()` functions respectively. Those are the logit equivalents of the `qnorm()` and `pnorm()` functions you encountered in @sec-gaussian.\n\n\n::: {.cell}\n\n```{.r .cell-code}\np <- 0.3\n\n# from probability to log-odds\nlog_odds <- qlogis(p)\nlog_odds\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.8472979\n```\n\n\n:::\n\n```{.r .cell-code}\n# from log-odds to probability\nplogis(log_odds)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.3\n```\n\n\n:::\n:::\n\n\n## Fitting a Bernoulli model\n\n::: {.callout-warning collapse=\"true\"}\n### Spotlight: Bernoulli, binomial and logistic regression\n\nA lot of researchers know Bernoulli models under the name \"binomial\" or \"logistic\" regression. Please, note that these are exactly equivalent: they refer to a model with a Bernoulli distribution for the outcome variable. It is just that different research traditions call them differently.\n\nSo if somebody asks you to run a logistic regression, or if you read a paper that reports one, what they just mean is to run a regression with a binary outcome variable and a Bernoulli distribution!\n:::\n\nTo illustrate how to fit a Bernoulli model, we will use data from @brentari2024 on the emergent Nicaraguan Sign Language (*Lengua de Señas Nicaragüense*, NSL).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverb_org <- read_csv(\"data/brentari2024/verb_org.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 630 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Group, Object, Number, Agency, Num_Predicates\ndbl (1): Participant\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\n`verb_org` contains information on predicates as signed by three groups (`Group`): home-signers (`homesign`), first generation NSL signers (`NSL1`) and second generation NSL signers (`NSL2`). Specifically, the data coded in `Num_Predicates` whether the predicates uttered by the signer were single-verb predicates (SVP, `single`) or a multi-verb predicates (MVP, `multiple`). The hypothesis of the study is that use of multi-verb predicates would increase with each generation, i.e. that NSL1 signers would use more MVPs than home-signers and that NSL2 signers would use more MVPs than home-signers and NSL1 signers. (For the linguistic reasons behind this hypothesis, check the paper linked above).\n\nLet's plot the data to learn a bit more about it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverb_org |> \n  ggplot(aes(Group, fill = Num_Predicates)) +\n  geom_bar(position = \"fill\")\n```\n\n::: {.cell-output-display}\n![](ch-regression-bernoulli_files/figure-html/verb-org-plot-1.png){width=672}\n:::\n:::\n\n\nWhat do you notice about the type of predicates in the three groups?\n\nTo assess the study hypothesis, we can fit a Bernoulli model with `Num_Predicates` as the outcome variable and `Group` as the predictor.\n\nBefore we move on onto fitting the model, it is useful to transform `Num_Predicates` into a factor and specify the order of the levels so that `single` is the first level and `multiple` is the second level.\n\nThis is useful because Bernoulli models estimate the probability (the parameter $p$ in $Bernoulli(p)$ of getting the *second* level in the outcome variable.\n\nYou can also think of this in terms of `0`s and `1`s: the first level is assigned to `0` and the second level is assigned to `1`. Then a Bernoulli distribution with probability $p$ tells you the probability of getting a `1`. It doesn't matter how you prefer to think about Bernoulli distributions, as long as you remember that the probability being estimated is the probability of the *second* level.\n\nNow let's mutate `verb_org`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nverb_org <- verb_org |> \n  mutate(\n    Num_Predicates = factor(Num_Predicates, levels = c(\"single\", \"multiple\"))\n  )\n```\n:::\n\n\nIf you reproduce the plot above you will see now that the order of `Num_Predicates` in the legend is \"single\" then \"multiple\" and that the order of the proportions in the bar chart have flipped.\n\nNow we can move on onto modelling.\n\n$$\n\\begin{align}\n\\text{Num\\_Preds}_{MVP} & \\sim Bernoulli(p_i) \\\\\nlogit(p_i) & = \\alpha_{\\text{Group}[i]} \\\\\n\\end{align}\n$$\n\n-   The probability of using an MVP follows a Bernoulli distribution with probability $p$.\n\n-   The log-odds of $p$ are equal to $\\alpha$ for each Group.\n\nIn other words, the model estimates $p$ for each group. Here is the code. Remember that to use the indexing approach for categorical predictors (`Group`) we need to suppress the intercept with the `0 +` syntax.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmvp_bm <- brm(\n  Num_Predicates ~ 0 + Group,\n  family = bernoulli,\n  data = verb_org,\n  cores = 4,\n  seed = 1329,\n  file = \"cache/ch-regression-bernoulli_mvp_bm\"\n)\n```\n:::\n\n\nLet's inspect the model summary (we will get 80% CrIs).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mvp_bm, prob = 0.8)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: bernoulli \n  Links: mu = logit \nFormula: Num_Predicates ~ 0 + Group \n   Data: verb_org (Number of observations: 630) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n              Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS\nGrouphomesign    -0.57      0.15    -0.76    -0.38 1.00     4424     3005\nGroupNSL1        -1.46      0.17    -1.68    -1.24 1.00     3797     2995\nGroupNSL2        -0.02      0.14    -0.21     0.16 1.00     4020     2851\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\nBased on the model, there is an 80% probability that the log-odds of a MVP are between -0.76 and -0.38 in home-signers, between -1.68 and -1.24 in NSL1 signers and between -0.21 and 0.16 in NSL2 signers.\n\nIt's easier to understand the results if we convert the log-odds to probabilities. The quickest way to do this is to get the `Regression Coefficients` table from the summary with `fixef()` and mutate the `Q` columns with `plogis()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfixef(mvp_bm, prob = c(0.1, 0.9)) |>\n  # we need to convert the output of fixef() to a tibble to use mutate()\n  as_tibble() |>\n  # we plogis() the Q columns and round to the second digit\n  mutate(\n    Q10 = round(plogis(Q10), 2),\n    Q90 = round(plogis(Q90), 2)\n  )\n```\n\n::: {.cell-output-display}\n`````{=html}\n<div data-pagedtable=\"false\">\n  <script data-pagedtable-source type=\"application/json\">\n{\"columns\":[{\"label\":[\"Estimate\"],\"name\":[1],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Est.Error\"],\"name\":[2],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Q10\"],\"name\":[3],\"type\":[\"dbl\"],\"align\":[\"right\"]},{\"label\":[\"Q90\"],\"name\":[4],\"type\":[\"dbl\"],\"align\":[\"right\"]}],\"data\":[{\"1\":\"-0.56829323\",\"2\":\"0.1491146\",\"3\":\"0.32\",\"4\":\"0.41\"},{\"1\":\"-1.46278058\",\"2\":\"0.1712857\",\"3\":\"0.16\",\"4\":\"0.22\"},{\"1\":\"-0.02278583\",\"2\":\"0.1415461\",\"3\":\"0.45\",\"4\":\"0.54\"}],\"options\":{\"columns\":{\"min\":{},\"max\":[10]},\"rows\":{\"min\":[10],\"max\":[10]},\"pages\":{}}}\n  </script>\n</div>\n`````\n:::\n:::\n\n\nBased on the model, there is an 80% probability that the probability of using an MVP is between 32-41% in home-signers, between 16-22% in NSL1 signers and between 45-54% in NSL2 signers.\n\nWe can now see more clearly that the hypothesis of the study is not fully borne out by the data: while NSL2 signers are more likely to use an MVP than home-signers and NSL1 signers, it is not the case that NSL1 signers are more likely to use MVPs than home-signers.\n\nTo conclude this introduction to Bernoulli models (aka binomial/logistic regressions) we can get the predicted probabilities of use of MVPs in the three groups with `conditional_effects()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconditional_effects(mvp_bm)\n```\n\n::: {.cell-output-display}\n![](ch-regression-bernoulli_files/figure-html/mvp-bm-cond-1.png){width=672}\n:::\n:::\n\n",
    "supporting": [
      "ch-regression-bernoulli_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"site_libs/pagedtable-1.1/css/pagedtable.css\" rel=\"stylesheet\" />\n<script src=\"site_libs/pagedtable-1.1/js/pagedtable.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}